import asyncio
import logging
import threading
import time
import queue
from datetime import datetime
import numpy as np
from typing import Optional, Dict, Any, Callable
from enum import Enum

from services.stream_stt import RTZROpenAPIClient
from core.graph import OptimizedVoicePhishingGraph
from services.tts_service import tts_service
from services.audio_manager import audio_manager
from config.settings import settings
from core.state import VictimRecoveryState

logger = logging.getLogger(__name__)

class ConversationState(Enum):
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    SPEAKING = "speaking"
    ERROR = "error"

class HighPerformanceConversationManager:
    """
    ê³ ì„±ëŠ¥ ëŒ€í™” ê´€ë¦¬ì
    - ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
    - ì‹¤ì‹œê°„ ì‘ë‹µ ìµœì í™”
    - í–¥ìƒëœ ì˜¤ë””ì˜¤ ë™ê¸°í™”
    """
    
    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        
        # ìµœì í™”ëœ ì»´í¬ë„ŒíŠ¸ë“¤
        self.stt_client = None
        self.langgraph = OptimizedVoicePhishingGraph(debug=settings.DEBUG)
        self.tts_service = tts_service
        self.audio_manager = audio_manager
        
        # ìƒíƒœ ê´€ë¦¬
        self.conversation_state = ConversationState.IDLE
        self.current_langgraph_state = None
        self.session_id = None
        
        # ê³ ì„±ëŠ¥ ì œì–´ í”Œë˜ê·¸
        self.is_running = False
        self.is_listening = False
        self.is_processing = False
        
        # ìµœì í™”ëœ STT ê²°ê³¼ í (í¬ê¸° ì œí•œ)
        self.stt_queue = queue.Queue(maxsize=10)
        self.stt_lock = threading.Lock()
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        self.callbacks = {
            'on_user_speech': None,
            'on_ai_response': None,
            'on_state_change': None
        }
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'conversation_start_time': None,
            'total_turns': 0,
            'avg_response_time': 0.0,
            'stt_accuracy': 0.0,
            'tts_success_rate': 0.0
        }
        
        # ì‘ë‹µ ì‹œê°„ ì¶”ì 
        self.response_times = []
        self.max_response_times = 50  # ìµœê·¼ 50ê°œë§Œ ìœ ì§€

        # ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§
        self.audio_monitor = {
            'is_monitoring' : False,
            'audio_level' : 0.0,
            'silence_threshold' : 0.015, # ì¹¨ë¬µ ì„ê³„ê°’
            'last_audio_time' : None,
            # 'silence_check_interval': 1  # 1ì´ˆë§ˆë‹¤ ì²´í¬
        }


        # ì¹¨ë¬µ ê°ì§€
        self.silence_detection = {
            'enabled': True,
            'timeout': 5.0,  # 5ì´ˆ ì¹¨ë¬µ ì‹œ ë‹¤ìŒìœ¼ë¡œ
            'last_speech_time': None,
            'last_audio_activity' : None, # ë§ˆì§€ë§‰ ì˜¤ë””ì˜¤ í™œë™ ì‹œê°„
            'is_first_interaction': True,  # ì²« ë²ˆì§¸ ìƒí˜¸ì‘ìš© ì²´í¬
            'min_interactions': 1,  # ìµœì†Œ ìƒí˜¸ì‘ìš© íšŸìˆ˜
            'silence_check_interval': 0.2 
        }

    def _start_audio_monitoring(self):
        """ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        
        def audio_monitor_worker():
            """ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì›Œì»¤"""
            try:
                import pyaudio
                
                # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
                chunk = 1024
                format = pyaudio.paInt16
                channels = 1
                rate = 16000
                
                p = pyaudio.PyAudio()
                
                stream = p.open(
                    format=format,
                    channels=channels,
                    rate=rate,
                    input=True,
                    frames_per_buffer=chunk
                )
                
                self.audio_monitor['monitor_stream'] = stream
                self.audio_monitor['is_monitoring'] = True
                
                logger.info("ğŸ¤ ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
                
                while self.is_running and self.audio_monitor['is_monitoring']:
                    try:
                        # ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸°
                        data = stream.read(chunk, exception_on_overflow=False)
                        
                        # ìŒì„± ë ˆë²¨ ê³„ì‚°
                        audio_data = np.frombuffer(data, dtype=np.int16)
                        audio_level = np.abs(audio_data).mean() / 32768.0  # ì •ê·œí™”
                        
                        self.audio_monitor['audio_level'] = audio_level
                        
                        # ìŒì„± í™œë™ ê°ì§€
                        if audio_level > self.audio_monitor['silence_threshold']:
                            self.audio_monitor['last_audio_time'] = time.time()
                            self.silence_detection['last_audio_activity'] = time.time()
                            
                            if settings.DEBUG:
                                logger.debug(f"ğŸ”Š ì˜¤ë””ì˜¤ ë ˆë²¨: {audio_level:.3f}")
                        
                    except Exception as e:
                        if self.is_running:
                            logger.error(f"ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                        break
                
                # ì •ë¦¬
                stream.stop_stream()
                stream.close()
                p.terminate()
                
            except Exception as e:
                logger.error(f"ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            finally:
                self.audio_monitor['is_monitoring'] = False
        
        # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
        monitor_thread = threading.Thread(target=audio_monitor_worker, daemon=True)
        monitor_thread.start()
    
    def _should_handle_silence(self) -> bool:
        """ê°œì„ ëœ ì¹¨ë¬µ ì²˜ë¦¬ ì—¬ë¶€ íŒë‹¨"""
        
        # ì¹¨ë¬µ ê°ì§€ ë¹„í™œì„±í™” ìƒíƒœ
        if not self.silence_detection['enabled']:
            return False
        
        # ì²« ë²ˆì§¸ ìƒí˜¸ì‘ìš©ì´ë©´ ì¹¨ë¬µ ê°ì§€ ì•ˆ í•¨
        if self.silence_detection['is_first_interaction']:
            return False
        
        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì´ë©´ ì¹¨ë¬µ ê°ì§€ ì•ˆ í•¨
        if self.is_processing:
            return False
        
        current_time = time.time()
        
        # 1. STT ê¸°ë°˜ ì²´í¬ (ìŒì„± ì¸ì‹ëœ ì‹œê°„)
        last_speech_time = self.silence_detection.get('last_speech_time')
        speech_silence_duration = float('inf')
        if last_speech_time:
            speech_silence_duration = current_time - last_speech_time
        
        # 2. ì˜¤ë””ì˜¤ í™œë™ ê¸°ë°˜ ì²´í¬ (ì‹¤ì œ ì†Œë¦¬ ê°ì§€)
        last_audio_time = self.silence_detection.get('last_audio_activity')
        audio_silence_duration = float('inf')
        if last_audio_time:
            audio_silence_duration = current_time - last_audio_time
        
        # ë‘˜ ì¤‘ ë” ì§§ì€ ì‹œê°„ ì‚¬ìš© (ë” ì •í™•í•œ ê°ì§€)
        silence_duration = min(speech_silence_duration, audio_silence_duration)
        
        # ë””ë²„ê·¸ ì •ë³´
        if settings.DEBUG and silence_duration < 60:  # 1ë¶„ ì´ë‚´ë§Œ ë¡œê¹…
            logger.debug(f"ğŸ”‡ ì¹¨ë¬µ ì²´í¬: {silence_duration:.1f}ì´ˆ (ì„ê³„ê°’: {self.silence_detection['timeout']}ì´ˆ)")
        
        # ì¹¨ë¬µ ì„ê³„ê°’ ì²´í¬
        is_silence = silence_duration >= self.silence_detection['timeout']
        
        if is_silence:
            logger.info(f"â° ì¹¨ë¬µ ê°ì§€ë¨: {silence_duration:.1f}ì´ˆ")
        
        return is_silence
    
    def get_audio_status(self) -> dict:
        """ì˜¤ë””ì˜¤ ìƒíƒœ ì¡°íšŒ (ë””ë²„ê¹…ìš©)"""
        
        current_time = time.time()
        
        return {
            'is_monitoring': self.audio_monitor['is_monitoring'],
            'current_audio_level': self.audio_monitor['audio_level'],
            'silence_threshold': self.audio_monitor['silence_threshold'],
            'last_audio_time': self.audio_monitor.get('last_audio_time'),
            'seconds_since_audio': (
                current_time - self.audio_monitor['last_audio_time'] 
                if self.audio_monitor.get('last_audio_time') else None
            ),
            'silence_detection_enabled': self.silence_detection['enabled'],
            'silence_timeout': self.silence_detection['timeout']
        }



        
    async def initialize(self) -> bool:
        """ê³ ì„±ëŠ¥ ì´ˆê¸°í™”"""
        logger.info("ğŸš€ ê³ ì„±ëŠ¥ ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”...")
        
        try:
            # STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì„±ëŠ¥ ìµœì í™”)
            self.stt_client = RTZROpenAPIClient(self.client_id, self.client_secret)
            logger.info("âœ… STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # TTS ì„œë¹„ìŠ¤ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
            if await asyncio.wait_for(self.tts_service.test_connection(), timeout=5.0):
                logger.info("âœ… TTS ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸")
                self.performance_stats['tts_success_rate'] = 1.0
            else:
                logger.warning("âš ï¸ TTS ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                self.performance_stats['tts_success_rate'] = 0.0
            
            # ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            if self.audio_manager.initialize_output():
                logger.info("âœ… ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.error("âŒ ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
            
            # LangGraph ìµœì í™” ì‹œì‘
            self.current_langgraph_state = await asyncio.wait_for(
                self.langgraph.start_conversation(), 
                timeout=3.0
            )
            
            if self.current_langgraph_state:
                self.session_id = self.current_langgraph_state['session_id']
                logger.info(f"âœ… LangGraph ì‹œì‘ - ì„¸ì…˜: {self.session_id}")
            else:
                logger.error("âŒ LangGraph ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
            
            # ì´ˆê¸° ì¸ì‚¬ë§ ì²˜ë¦¬
            await self._handle_initial_greeting()
            
            self.performance_stats['conversation_start_time'] = datetime.now()
            self._set_state(ConversationState.IDLE)
            
            return True
            
        except asyncio.TimeoutError:
            logger.error("âŒ ì´ˆê¸°í™” ì‹œê°„ ì´ˆê³¼")
            return False
        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._set_state(ConversationState.ERROR)
            return False
    
    async def start_conversation(self):
        """ìµœì í™”ëœ ëŒ€í™” ì‹œì‘"""
        if not await self.initialize():
            logger.error("âŒ ëŒ€í™” ì‹œì‘ ì‹¤íŒ¨")
            return
        
        self.is_running = True
        logger.info("ğŸ™ï¸ ê³ ì„±ëŠ¥ ëŒ€í™” ì‹œì‘")
        
        try:
            # STT ë¦¬ìŠ¤ë‹ ì‹œì‘ (ë³„ë„ ìŠ¤ë ˆë“œ)
            self._start_optimized_stt()
            
            # ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ (ê³ ì„±ëŠ¥)
            await self._main_conversation_loop()
            
        except KeyboardInterrupt:
            logger.info("ì‚¬ìš©ìì— ì˜í•œ ì¢…ë£Œ")
        except Exception as e:
            logger.error(f"ëŒ€í™” ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            await self.cleanup()

    async def _main_conversation_loop(self): 
        """ê³ ì„±ëŠ¥ ë©”ì¸ ë£¨í”„ - ì¹¨ë¬µ ê°ì§€ ê°•í™”"""
        
        # ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        logger.info("ğŸ¤ ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹œë„...")
        self._start_audio_monitoring()
        
        # ì ì‹œ ëŒ€ê¸°í•´ì„œ ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ë„ë¡
        await asyncio.sleep(1)
        
        # ì¹¨ë¬µ ì²´í¬ë¥¼ ìœ„í•œ ë§ˆì§€ë§‰ ì²´í¬ ì‹œê°„
        last_silence_check = time.time()
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # STT ê²°ê³¼ í™•ì¸
                user_input = self._get_stt_result_fast()
                
                if user_input and not self.is_processing:
                    # ìŒì„± ì…ë ¥ì´ ìˆìœ¼ë©´ ì‹œê°„ ì—…ë°ì´íŠ¸
                    self.silence_detection['last_speech_time'] = current_time
                    self.silence_detection['is_first_interaction'] = False
                    
                    await self._process_user_input_optimized(user_input)
                
                # ì •ê¸°ì ì¸ ì¹¨ë¬µ ì²´í¬ (0.5ì´ˆë§ˆë‹¤)
                if (current_time - last_silence_check >= 
                    self.silence_detection['silence_check_interval']):
                    
                    if self._should_handle_silence():
                        await self._handle_silence_timeout()
                    
                    last_silence_check = current_time
                
                # ëŒ€í™” ì™„ë£Œ í™•ì¸
                if self._should_end_conversation():
                    logger.info("âœ… ëŒ€í™” ìë™ ì™„ë£Œ")
                    break
                
                await asyncio.sleep(0.1)
                        
            except Exception as e:
                logger.error(f"ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(0.5)
        
    def _start_optimized_stt(self):
        """ìµœì í™”ëœ STT ì‹œì‘"""
        
        def optimized_stt_worker():
            """ì„±ëŠ¥ ìµœì í™”ëœ STT ì›Œì»¤"""
            try:
                self.stt_client.reset_stream()
                
                # ì»¤ìŠ¤í…€ ì½œë°±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
                def fast_transcript_handler(start_time, transcript, is_final=False):
                    if is_final and transcript.alternatives:
                        text = transcript.alternatives[0].text.strip()
                        if text and len(text) > 1:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ í•„í„°ë§
                            try:
                                # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì˜¤ë˜ëœ í•­ëª© ì œê±°
                                if self.stt_queue.full():
                                    try:
                                        self.stt_queue.get_nowait()
                                    except queue.Empty:
                                        pass
                                
                                self.stt_queue.put_nowait(text)
                                
                            except queue.Full:
                                logger.warning("STT í ê°€ë“ì°¸ - ë©”ì‹œì§€ ë¬´ì‹œ")
                
                # ì½œë°± ì„¤ì •
                self.stt_client.print_transcript = fast_transcript_handler
                
                # STT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
                # STT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
                while self.is_running:  # ì¢…ë£Œ ì¡°ê±´ ì¶”ê°€
                    try:
                        self.stt_client.transcribe_streaming_grpc()
                    except Exception as e:
                        if self.is_running:  # ì‹¤í–‰ ì¤‘ì¼ ë•Œë§Œ ì—ëŸ¬ ë¡œê·¸
                            logger.error(f"STT ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
                        break
                    
            except Exception as e:
                if self.is_running:
                    logger.error(f"STT ì›Œì»¤ ì˜¤ë¥˜: {e}")
                
            # except Exception as e:
            #     logger.error(f"STT ì›Œì»¤ ì˜¤ë¥˜: {e}")
            #     self._set_state(ConversationState.ERROR)
        
        # ë°ëª¬ ìŠ¤ë ˆë“œë¡œ ì‹œì‘
        stt_thread = threading.Thread(target=optimized_stt_worker, daemon=True)
        stt_thread.start()
        self.is_listening = True
        
        logger.info("ğŸ¤ ìµœì í™”ëœ STT ì‹œì‘")
    
    
    def _get_stt_result_fast(self) -> Optional[str]:
        """ê³ ì† STT ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            return self.stt_queue.get_nowait()
        except queue.Empty:
            return None
    
    async def _process_user_input_optimized(self, user_input: str):
        """ìµœì í™”ëœ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬"""
        
        start_time = time.time()
        self.is_processing = True
        
        logger.info(f"ğŸ‘¤ ì‚¬ìš©ì: {user_input}")
        
        # ìƒíƒœ ë³€ê²½
        self._set_state(ConversationState.PROCESSING)
        
        # ì½œë°± í˜¸ì¶œ
        if self.callbacks['on_user_speech']:
            self.callbacks['on_user_speech'](user_input)
        
        try:
            # LangGraph ìµœì í™” ì²˜ë¦¬ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
            self.current_langgraph_state = await asyncio.wait_for(
                self.langgraph.continue_conversation(
                    self.current_langgraph_state, 
                    user_input
                ),
                timeout=10.0  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ / ì§§ê²Œ ì¤¬ëŠ”ë° ë„ˆë¬´ ë¹¨ë¦¬ íƒ€ì„ì•„ì›ƒë¨.
            )
            
            # AI ì‘ë‹µ ì¶”ì¶œ ë° ì²˜ë¦¬
            await self._handle_ai_response()
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_performance_stats(processing_time)
            
            self.performance_stats['total_turns'] += 1
            
            # ë‹¤ìŒ ìƒíƒœë¡œ ì „í™˜
            if self._is_conversation_complete():
                await self.stop_conversation()
            else:
                self._set_state(ConversationState.LISTENING)
            
        except asyncio.TimeoutError:
            logger.warning("â° ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ - ë¹ ë¥¸ ì‘ë‹µ ìƒì„±")
            await self._handle_timeout_response(user_input)
        except Exception as e:
            logger.error(f"ì…ë ¥ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self._handle_error("ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
        finally:
            self.is_processing = False

    async def continue_conversation(self, state: VictimRecoveryState, user_input: str) -> VictimRecoveryState:
        """êµ¬ì¡°í™”ëœ ëŒ€í™” ê³„ì†í•˜ê¸°"""
        
        if not user_input.strip():
            state["messages"].append({
                "role": "assistant",
                "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "timestamp": datetime.now()
            })
            return state
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        state["messages"].append({
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now()
        })
        
        state["conversation_turns"] = state.get("conversation_turns", 0) + 1
        
        try:
            # ğŸ”§ ìˆ˜ì •: ê·¸ë˜í”„ ì¬ì‹¤í–‰ìœ¼ë¡œ ìë™ íë¦„ ì§„í–‰
            config = {"recursion_limit": 5}
            updated_state = await self.langgraph.graph.ainvoke(state, config)
            
            if self.debug:
                print(f"âœ… êµ¬ì¡°í™”ëœ ì²˜ë¦¬: í„´ {updated_state['conversation_turns']}")
            
            return updated_state
            
        except Exception as e:
            if self.debug:
                print(f"âŒ êµ¬ì¡°í™”ëœ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            state["messages"].append({
                "role": "assistant",
                "content": "ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê¸´ê¸‰í•œ ê²½ìš° 112ë¡œ ì—°ë½í•˜ì„¸ìš”.",
                "timestamp": datetime.now()
            })
            return state
    
    async def _handle_ai_response(self):
        """AI ì‘ë‹µ ì²˜ë¦¬"""
        
        if not self.current_langgraph_state or not self.current_langgraph_state.get('messages'):
            return
        
        last_message = self.current_langgraph_state['messages'][-1]
        if last_message.get('role') != 'assistant':
            return
        
        ai_response = last_message['content']
        logger.info(f"AI: {ai_response[:100]}...")
        
        # ì½œë°± í˜¸ì¶œ
        if self.callbacks['on_ai_response']:
            self.callbacks['on_ai_response'](ai_response)
        
        # TTS ì²˜ë¦¬ (ë¹„ë™ê¸°)
        await self._speak_response_optimized(ai_response)
    
    async def _speak_response_optimized(self, text: str):
        """ìµœì í™”ëœ TTS ì²˜ë¦¬"""
        
        self._set_state(ConversationState.SPEAKING)
        
        try:
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ìµœì í™” (ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½)
            if len(text) > 300:
                text = self._summarize_text(text)
            
            # TTS ìŠ¤íŠ¸ë¦¼ ìƒì„± (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
            audio_stream = await asyncio.wait_for(
                self._create_tts_stream(text),
                timeout=5.0
            )
            
            # ì˜¤ë””ì˜¤ ì¬ìƒ
            await self.audio_manager.play_audio_stream(audio_stream)
            
            logger.info("ğŸ”Š TTS ì¬ìƒ ì™„ë£Œ")
            
        except asyncio.TimeoutError:
            logger.warning("â° TTS ì‹œê°„ ì´ˆê³¼ - í…ìŠ¤íŠ¸ ì¶œë ¥ìœ¼ë¡œ ëŒ€ì²´")
            print(f"AI: {text}")
        except Exception as e:
            logger.error(f"TTS ì˜¤ë¥˜: {e}")
            # TTS ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ì¶œë ¥
            print(f"AI: {text}")
            self.performance_stats['tts_success_rate'] *= 0.9  # ì„±ê³µë¥  ê°ì†Œ
    
    async def _create_tts_stream(self, text: str):
        """TTS ìŠ¤íŠ¸ë¦¼ ìƒì„±"""
        return self.tts_service.text_to_speech_stream(text)
    
    def _summarize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ìš”ì•½ (ê°„ë‹¨í•œ ë°©ì‹)"""
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        
        # ì¤‘ìš”í•œ ë¬¸ì¥ë“¤ë§Œ ì„ íƒ (í‚¤ì›Œë“œ ê¸°ë°˜)
        important_keywords = ['ê¸´ê¸‰', 'ì¦‰ì‹œ', 'ì‹ ê³ ', '112', 'ì¤‘ìš”', 'ì£¼ì˜']
        important_sentences = []
        
        for sentence in sentences[:3]:  # ìµœëŒ€ 3ë¬¸ì¥
            if any(keyword in sentence for keyword in important_keywords):
                important_sentences.append(sentence)
        
        if important_sentences:
            return '. '.join(important_sentences) + '.'
        else:
            # ì¤‘ìš” ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì²˜ìŒ 2ë¬¸ì¥
            return '. '.join(sentences[:2]) + '.'
    
    async def _handle_timeout_response(self, user_input: str):
        """íƒ€ì„ì•„ì›ƒ ì‹œ ë¹ ë¥¸ ì‘ë‹µ"""
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ì‘ë‹µ
        user_lower = user_input.lower()
        
        if any(word in user_lower for word in ['ëˆ', 'ì†¡ê¸ˆ', 'ë³´ëƒˆ', 'ê³„ì¢Œ', 'ì´ì²´', 'ê³„ì¢Œì´ì²´']):
            quick_response = "ê¸´ê¸‰ ìƒí™©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì¦‰ì‹œ 112ì— ì‹ ê³ í•˜ì„¸ìš”."
        else:
            quick_response = "ìƒí™©ì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."
        
        # ì§ì ‘ ì‘ë‹µ ì¶”ê°€
        if self.current_langgraph_state:
            self.current_langgraph_state['messages'].append({
                "role": "assistant",
                "content": quick_response,
                "timestamp": datetime.now(),
                "type": "timeout_response"
            })
        
        await self._speak_response_optimized(quick_response)
    
    async def _handle_initial_greeting(self):
        """ì´ˆê¸° ì¸ì‚¬ë§ ì²˜ë¦¬"""
        
        if self.current_langgraph_state and self.current_langgraph_state.get('messages'):
            greeting = self.current_langgraph_state['messages'][-1]['content']
            logger.info("ğŸ”Š ì´ˆê¸° ì¸ì‚¬ë§ ì¬ìƒ")
            await self._speak_response_optimized(greeting)
    
    async def _handle_error(self, error_message: str):
        """ì˜¤ë¥˜ ì²˜ë¦¬"""
        
        self._set_state(ConversationState.ERROR)
        logger.error(f"ì˜¤ë¥˜ ì²˜ë¦¬: {error_message}")
        
        # ì˜¤ë¥˜ ë©”ì‹œì§€ ì¬ìƒ
        await self._speak_response_optimized(error_message)
        
        # ë¦¬ìŠ¤ë‹ ìƒíƒœë¡œ ë³µê·€
        self._set_state(ConversationState.LISTENING)
    
    def _should_end_conversation(self) -> bool:
        """ëŒ€í™” ì¢…ë£Œ ì—¬ë¶€ íŒë‹¨"""
        
        if not self.current_langgraph_state:
            return False
        
        # ì™„ë£Œ ìƒíƒœ í™•ì¸
        if self.current_langgraph_state.get('current_step') == 'consultation_complete':
            return True
        
        current_step = self.current_langgraph_state.get('current_step')
        if current_step == 'consultation_complete':
            return True
        
        # ë‚˜ë¨¸ì§€ ì¡°ê±´ë“¤ì€ ë” ê´€ëŒ€í•˜ê²Œ
        if self.performance_stats['total_turns'] >= 20:  # 20í„´ìœ¼ë¡œ ì¦ê°€
            return True
        
        # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ í™•ì¸
        if self.performance_stats['conversation_start_time']:
            elapsed = (datetime.now() - self.performance_stats['conversation_start_time']).total_seconds()
            if elapsed > settings.SESSION_TIMEOUT:
                return True
        
        return False
    
    def _is_conversation_complete(self) -> bool:
        """ëŒ€í™” ì™„ë£Œ ì—¬ë¶€ í™•ì¸ (ê°„ë‹¨í•œ ë²„ì „)"""
        return self._should_end_conversation()
    
    def _update_performance_stats(self, processing_time: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        # ì‘ë‹µ ì‹œê°„ ì¶”ê°€
        self.response_times.append(processing_time)
        
        # ìµœëŒ€ ê°œìˆ˜ ìœ ì§€
        if len(self.response_times) > self.max_response_times:
            self.response_times.pop(0)
        
        # í‰ê·  ê³„ì‚°
        if self.response_times:
            self.performance_stats['avg_response_time'] = sum(self.response_times) / len(self.response_times)
    
    def _set_state(self, new_state: ConversationState):
        """ìƒíƒœ ë³€ê²½"""
        
        if self.conversation_state != new_state:
            old_state = self.conversation_state
            self.conversation_state = new_state
            
            logger.debug(f"ìƒíƒœ ë³€ê²½: {old_state.value} â†’ {new_state.value}")
            
            # ì½œë°± í˜¸ì¶œ
            if self.callbacks['on_state_change']:
                self.callbacks['on_state_change'](old_state, new_state)
    
    async def stop_conversation(self):
        """ëŒ€í™” ì¤‘ì§€"""
        
        logger.info("ğŸ›‘ ëŒ€í™” ì¤‘ì§€")
        
        self.is_running = False
        self.is_listening = False
        
        # ë§ˆì§€ë§‰ ì¸ì‚¬ë§
        farewell = "ìƒë‹´ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•ˆì „í•˜ì„¸ìš”!"
        await self._speak_response_optimized(farewell)
    
    async def cleanup(self):
        """ìµœì í™”ëœ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        
        logger.info("ğŸ§¹ ê³ ì„±ëŠ¥ ë§¤ë‹ˆì € ì •ë¦¬ ì¤‘...")
        
        try:
            self.is_running = False
            self.is_listening = False
            self.is_processing = False
            
            # STT ì •ë¦¬
            # if self.stt_client and hasattr(self.stt_client, 'stream'):
            #     self.stt_client.stream.terminate()

            # STT ìŠ¤íŠ¸ë¦¼ ê°•ì œ ì¢…ë£Œ
            if self.stt_client and hasattr(self.stt_client, 'stream'):
                try:
                    self.stt_client.stream.terminate()
                except:
                    pass
                
            # í ì •ë¦¬
            while not self.stt_queue.empty():
                try:
                    self.stt_queue.get_nowait()
                except queue.Empty:
                    break
            
            # ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì •ë¦¬
            self.audio_manager.cleanup()
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self.langgraph, 'clear_cache'):
                self.langgraph.clear_cache()
            
            # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
            self._print_performance_stats()
            
            logger.info("âœ… ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _print_performance_stats(self):
        """ì„±ëŠ¥ í†µê³„ ì¶œë ¥"""
        
        stats = self.performance_stats
        
        if stats['conversation_start_time']:
            total_time = (datetime.now() - stats['conversation_start_time']).total_seconds()
            
            logger.info("ğŸ“Š ì„±ëŠ¥ í†µê³„:")
            logger.info(f"   ì´ ëŒ€í™” ì‹œê°„: {total_time:.1f}ì´ˆ")
            logger.info(f"   ì´ ëŒ€í™” í„´: {stats['total_turns']}")
            logger.info(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['avg_response_time']:.3f}ì´ˆ")
            logger.info(f"   TTS ì„±ê³µë¥ : {stats['tts_success_rate']:.1%}")
            
            if self.response_times:
                logger.info(f"   ìµœëŒ€ ì‘ë‹µ ì‹œê°„: {max(self.response_times):.3f}ì´ˆ")
                logger.info(f"   ìµœì†Œ ì‘ë‹µ ì‹œê°„: {min(self.response_times):.3f}ì´ˆ")
    
    # ========================================================================
    # ê³µê°œ ë©”ì„œë“œë“¤
    # ========================================================================
    
    def get_conversation_status(self) -> Dict[str, Any]:
        """í–¥ìƒëœ ëŒ€í™” ìƒíƒœ ì •ë³´"""
        
        elapsed_time = 0
        if self.performance_stats['conversation_start_time']:
            elapsed_time = (datetime.now() - self.performance_stats['conversation_start_time']).total_seconds()
        
        return {
            "state": self.conversation_state.value,
            "session_id": self.session_id,
            "total_turns": self.performance_stats['total_turns'],
            "is_running": self.is_running,
            "is_listening": self.is_listening,
            "is_processing": self.is_processing,
            "elapsed_time": elapsed_time,
            "avg_response_time": self.performance_stats['avg_response_time'],
            "tts_success_rate": self.performance_stats['tts_success_rate'],
            "queue_size": self.stt_queue.qsize()
        }
    
    def set_callbacks(self, 
                     on_user_speech: Optional[Callable] = None,
                     on_ai_response: Optional[Callable] = None, 
                     on_state_change: Optional[Callable] = None):
        """ì½œë°± í•¨ìˆ˜ ì„¤ì •"""
        
        if on_user_speech:
            self.callbacks['on_user_speech'] = on_user_speech
        if on_ai_response:
            self.callbacks['on_ai_response'] = on_ai_response
        if on_state_change:
            self.callbacks['on_state_change'] = on_state_change

    async def _handle_silence_timeout(self):  # ğŸ‘ˆ ì—¬ê¸°ì— ì¶”ê°€
        """ì¹¨ë¬µ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬"""
        
        logger.info("â° ì¹¨ë¬µ ê°ì§€ - ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì§„í–‰")
        
        # ì¹¨ë¬µ ê°ì§€ ì‹œê°„ ë¦¬ì…‹
        self.silence_detection['last_speech_time'] = time.time()
        self.silence_detection['last_audio_activity'] = time.time()
        
        # ìƒí™©ì— ë”°ë¥¸ í›„ì† ì§ˆë¬¸ ìƒì„±
        follow_up_question = self._generate_follow_up_question()
        
        # í›„ì† ì§ˆë¬¸ ì „ì†¡
        await self._send_follow_up_question(follow_up_question)

    def _generate_follow_up_question(self) -> str:  # ğŸ‘ˆ ì—¬ê¸°ì— ì¶”ê°€
        """ìƒí™©ì— ë§ëŠ” í›„ì† ì§ˆë¬¸ ìƒì„±"""
        
        if not self.current_langgraph_state:
            return "í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"
        
        urgency = self.current_langgraph_state.get('urgency_level', 3)
        conversation_turns = self.performance_stats['total_turns']
        
        # ê¸´ê¸‰ ìƒí™© í›„ì† ì§ˆë¬¸
        if urgency >= 8:
            questions = [
                "ì§€ê¸ˆ ì‹ ê³  ì§„í–‰í•˜ê³  ê³„ì‹ ê°€ìš”?",
                "ì¶”ê°€ë¡œ í•„ìš”í•œ ì¡°ì¹˜ê°€ ìˆë‚˜ìš”?",
                "ë‹¤ë¥¸ í”¼í•´ëŠ” ì—†ìœ¼ì‹ ê°€ìš”?"
            ]
        elif urgency >= 6:
            questions = [
                "ë” ìì„¸í•œ ìƒí™©ì„ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?",
                "ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?",
                "ì¶”ê°€ë¡œ í™•ì¸í•˜ê³  ì‹¶ì€ ë‚´ìš©ì´ ìˆë‚˜ìš”?"
            ]
        else:
            questions = [
                "ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "ë” ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‚˜ìš”?",
                "í˜¹ì‹œ ë†“ì¹œ ë¶€ë¶„ì´ ìˆì„ê¹Œìš”?"
            ]
        
        # ëŒ€í™” í„´ì— ë”°ë¼ ì§ˆë¬¸ ì„ íƒ
        question_index = min(conversation_turns, len(questions) - 1)
        return questions[question_index]

    async def _send_follow_up_question(self, question: str):  # ğŸ‘ˆ ì—¬ê¸°ì— ì¶”ê°€
        """í›„ì† ì§ˆë¬¸ ì „ì†¡"""
        
        try:
            # LangGraph ìƒíƒœì— AI ë©”ì‹œì§€ ì¶”ê°€
            if self.current_langgraph_state:
                self.current_langgraph_state['messages'].append({
                    "role": "assistant",
                    "content": question,
                    "timestamp": datetime.now(),
                    "metadata": {"type": "follow_up_silence"}
                })
            
            # ì½œë°± í˜¸ì¶œ
            if self.callbacks['on_ai_response']:
                self.callbacks['on_ai_response'](question)
            
            # TTSë¡œ ì¬ìƒ
            await self._speak_response_optimized(question)
            
        except Exception as e:
            logger.error(f"í›„ì† ì§ˆë¬¸ ì „ì†¡ ì˜¤ë¥˜: {e}")    
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ì§€í‘œ ì¡°íšŒ"""
        
        return {
            **self.performance_stats,
            "current_queue_size": self.stt_queue.qsize(),
            "response_time_history": self.response_times.copy(),
            "memory_usage": len(self.current_langgraph_state.get('messages', [])) if self.current_langgraph_state else 0
        }


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
ConversationManager = HighPerformanceConversationManager