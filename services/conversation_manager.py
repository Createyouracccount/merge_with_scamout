import asyncio
import logging
import threading
import time
import queue
from datetime import datetime
import numpy as np
from typing import Optional, Dict, Any, Callable
from enum import Enum

from services.stream_stt import RTZROpenAPIClient
from core.graph import VoiceFriendlyPhishingGraph
from services.tts_service import tts_service
from services.audio_manager import audio_manager
from config.settings import settings
from core.state import VictimRecoveryState

logger = logging.getLogger(__name__)

class ConversationState(Enum):
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    SPEAKING = "speaking"
    ERROR = "error"

class VoiceFriendlyConversationManager:
    """
    ìŒì„± ì¹œí™”ì  ëŒ€í™” ê´€ë¦¬ì
    - ì‘ë‹µ ì†ë„ ìµœìš°ì„  (3ì´ˆ ì´ë‚´)
    - ê°„ê²°í•œ ì‘ë‹µ (80ì ì´ë‚´)
    - ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì¹˜ ì•ˆë‚´
    - ì‹¤ì§ˆì  ë„ì›€ ì¤‘ì‹¬
    """
    
    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        
        # ìŒì„± ì¹œí™”ì  ì»´í¬ë„ŒíŠ¸ë“¤
        self.stt_client = None
        self.langgraph = VoiceFriendlyPhishingGraph(debug=settings.DEBUG)
        self.tts_service = tts_service
        self.audio_manager = audio_manager
        
        # ìƒíƒœ ê´€ë¦¬
        self.conversation_state = ConversationState.IDLE
        self.current_langgraph_state = None
        self.session_id = None
        
        # ë¹ ë¥¸ ì²˜ë¦¬ í”Œë˜ê·¸
        self.is_running = False
        self.is_listening = False
        self.is_processing = False
        
        # ê°„ë‹¨í•œ STT í (í¬ê¸° ì œí•œ)
        self.stt_queue = queue.Queue(maxsize=5)  # ë” ì‘ì€ í
        self.stt_lock = threading.Lock()
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        self.callbacks = {
            'on_user_speech': None,
            'on_ai_response': None,
            'on_state_change': None
        }
        
        # ê°„ë‹¨í•œ ì„±ëŠ¥ í†µê³„
        self.stats = {
            'conversation_start_time': None,
            'total_turns': 0,
            'avg_response_time': 0.0,
            'fast_responses': 0,  # 3ì´ˆ ì´ë‚´ ì‘ë‹µ
            'emergency_handled': 0
        }
        
        # ì‘ë‹µ ì‹œê°„ ì¶”ì  (ìµœê·¼ 5ê°œë§Œ)
        self.response_times = []
        self.max_response_history = 5
        
        # ì¹¨ë¬µ ê°ì§€ (ë” ì—¬ìœ ìˆê²Œ)
        self.silence_detection = {
            'enabled': True,
            'timeout': 8.0,  # 8ì´ˆë¡œ ì¦ê°€ (ì‚¬ìš©ì ìƒê° ì‹œê°„)
            'last_speech_time': None,
            'last_audio_activity': None,
            'is_first_interaction': True,
            'silence_check_interval': 0.5,  # 0.5ì´ˆë§ˆë‹¤ ì²´í¬ (ëœ ìì£¼)
            'min_silence_after_ai': 3.0     # AI ë‹µë³€ í›„ ìµœì†Œ 3ì´ˆ ëŒ€ê¸°
        }
        
        # ìŒì„± ë ˆë²¨ ëª¨ë‹ˆí„°ë§ (ëœ ë¯¼ê°í•˜ê²Œ)
        self.audio_monitor = {
            'is_monitoring': False,
            'audio_level': 0.0,
            'silence_threshold': 0.03,  # ëœ ë¯¼ê°í•˜ê²Œ (0.02 â†’ 0.03)
            'last_audio_time': None
        }
        
        # STT í’ˆì§ˆ ê´€ë¦¬
        self.stt_quality = {
            'min_text_length': 3,           # ìµœì†Œ 3ê¸€ì
            'last_ai_response_time': None,  # ë§ˆì§€ë§‰ AI ì‘ë‹µ ì‹œê°„
            'min_wait_after_ai': 2.0        # AI ì‘ë‹µ í›„ ìµœì†Œ 2ì´ˆ ëŒ€ê¸°
        }
    
    async def initialize(self) -> bool:
        """ë¹ ë¥¸ ì´ˆê¸°í™”"""
        logger.info("ğŸš€ ìŒì„± ì¹œí™”ì  ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”...")
        
        try:
            # STT í´ë¼ì´ì–¸íŠ¸ ë¹ ë¥¸ ì´ˆê¸°í™”
            self.stt_client = RTZROpenAPIClient(self.client_id, self.client_secret)
            logger.info("âœ… STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # TTS ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (2ì´ˆ íƒ€ì„ì•„ì›ƒ)
            if await asyncio.wait_for(self.tts_service.test_connection(), timeout=2.0):
                logger.info("âœ… TTS ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸")
            else:
                logger.warning("âš ï¸ TTS ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì§„í–‰")
            
            # ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            if self.audio_manager.initialize_output():
                logger.info("âœ… ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            # LangGraph ë¹ ë¥¸ ì‹œì‘ (2ì´ˆ íƒ€ì„ì•„ì›ƒ)
            self.current_langgraph_state = await asyncio.wait_for(
                self.langgraph.start_conversation(), 
                timeout=2.0
            )
            
            if self.current_langgraph_state:
                self.session_id = self.current_langgraph_state['session_id']
                logger.info(f"âœ… ìŒì„± ì¹œí™”ì  ìƒë‹´ ì‹œì‘ - ì„¸ì…˜: {self.session_id}")
            else:
                logger.error("âŒ LangGraph ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
            
            # ì´ˆê¸° ì¸ì‚¬ë§ ë¹ ë¥¸ ì²˜ë¦¬
            await self._handle_initial_greeting_fast()
            
            self.stats['conversation_start_time'] = datetime.now()
            self._set_state(ConversationState.IDLE)
            
            return True
            
        except asyncio.TimeoutError:
            logger.error("âŒ ì´ˆê¸°í™” ì‹œê°„ ì´ˆê³¼ (2ì´ˆ)")
            return False
        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def start_conversation(self):
        """ìŒì„± ì¹œí™”ì  ëŒ€í™” ì‹œì‘"""
        if not await self.initialize():
            logger.error("âŒ ëŒ€í™” ì‹œì‘ ì‹¤íŒ¨")
            return
        
        self.is_running = True
        logger.info("ğŸ™ï¸ ìŒì„± ì¹œí™”ì  ëŒ€í™” ì‹œì‘")
        
        try:
            # STT ë¹ ë¥¸ ì‹œì‘
            self._start_fast_stt()
            
            # ê°„ë‹¨í•œ ë©”ì¸ ë£¨í”„
            await self._simple_conversation_loop()
            
        except KeyboardInterrupt:
            logger.info("ì‚¬ìš©ìì— ì˜í•œ ì¢…ë£Œ")
        except Exception as e:
            logger.error(f"ëŒ€í™” ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            await self.cleanup()
    
    async def _simple_conversation_loop(self):
        """ê°„ë‹¨í•œ ë©”ì¸ ë£¨í”„"""
        
        # ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self._start_simple_audio_monitoring()
        
        last_silence_check = time.time()
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # STT ê²°ê³¼ ë¹ ë¥¸ í™•ì¸
                user_input = self._get_stt_result_immediate()
                
                if user_input and not self.is_processing:
                    # ìŒì„± ì…ë ¥ ì‹œê°„ ì—…ë°ì´íŠ¸
                    self.silence_detection['last_speech_time'] = current_time
                    self.silence_detection['is_first_interaction'] = False
                    
                    await self._process_user_input_fast(user_input)
                
                # ë¹ ë¥¸ ì¹¨ë¬µ ì²´í¬ (0.5ì´ˆë§ˆë‹¤)
                if (current_time - last_silence_check >= 
                    self.silence_detection['silence_check_interval']):
                    
                    if self._should_handle_silence_smart():
                        await self._handle_silence_fast()
                    
                    last_silence_check = current_time
                
                # ëŒ€í™” ì™„ë£Œ ì²´í¬
                if self._should_end_conversation_fast():
                    logger.info("âœ… ëŒ€í™” ì™„ë£Œ")
                    break
                
                await asyncio.sleep(0.2)  # ë” ì—¬ìœ ìˆëŠ” ë£¨í”„
                        
            except Exception as e:
                logger.error(f"ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(0.1)
    
    def _start_fast_stt(self):
        """ë¹ ë¥¸ STT ì‹œì‘"""
        
        def fast_stt_worker():
            """ë¹ ë¥¸ STT ì›Œì»¤"""
            try:
                self.stt_client.reset_stream()
                
                def immediate_transcript_handler(start_time, transcript, is_final=False):
                    if is_final and transcript.alternatives:
                        text = transcript.alternatives[0].text.strip()
                        if text and len(text) > 1:
                            try:
                                # íê°€ ê°€ë“ ì°¨ë©´ ì˜¤ë˜ëœ ê²ƒ ì œê±°
                                if self.stt_queue.full():
                                    try:
                                        self.stt_queue.get_nowait()
                                    except queue.Empty:
                                        pass
                                
                                self.stt_queue.put_nowait(text)
                                
                            except queue.Full:
                                pass  # ì¡°ìš©íˆ ë¬´ì‹œ
                
                self.stt_client.print_transcript = immediate_transcript_handler
                
                # STT ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
                while self.is_running:
                    try:
                        self.stt_client.transcribe_streaming_grpc()
                    except Exception as e:
                        if self.is_running:
                            logger.error(f"STT ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
                        break
                    
            except Exception as e:
                if self.is_running:
                    logger.error(f"ë¹ ë¥¸ STT ì›Œì»¤ ì˜¤ë¥˜: {e}")
        
        # ë¹ ë¥¸ ì‹œì‘
        stt_thread = threading.Thread(target=fast_stt_worker, daemon=True)
        stt_thread.start()
        self.is_listening = True
        
        logger.info("ğŸ¤ ë¹ ë¥¸ STT ì‹œì‘")
    
    def _start_simple_audio_monitoring(self):
        """ê°„ë‹¨í•œ ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§"""
        
        def simple_audio_monitor():
            try:
                import pyaudio
                
                chunk = 512  # ë” ì‘ì€ ì²­í¬
                p = pyaudio.PyAudio()
                
                stream = p.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=16000,
                    input=True,
                    frames_per_buffer=chunk
                )
                
                self.audio_monitor['is_monitoring'] = True
                
                while self.is_running and self.audio_monitor['is_monitoring']:
                    try:
                        data = stream.read(chunk, exception_on_overflow=False)
                        audio_data = np.frombuffer(data, dtype=np.int16)
                        audio_level = np.abs(audio_data).mean() / 32768.0
                        
                        self.audio_monitor['audio_level'] = audio_level
                        
                        if audio_level > self.audio_monitor['silence_threshold']:
                            self.audio_monitor['last_audio_time'] = time.time()
                            self.silence_detection['last_audio_activity'] = time.time()
                        
                    except Exception:
                        break
                
                stream.stop_stream()
                stream.close()
                p.terminate()
                
            except Exception as e:
                logger.error(f"ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            finally:
                self.audio_monitor['is_monitoring'] = False
        
        # ê°„ë‹¨í•œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        monitor_thread = threading.Thread(target=simple_audio_monitor, daemon=True)
        monitor_thread.start()
    
    def _get_stt_result_immediate(self) -> Optional[str]:
        """STT ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (í’ˆì§ˆ í•„í„°ë§)"""
        try:
            text = self.stt_queue.get_nowait()
            
            # í›„ì²˜ë¦¬ êµì • ì¶”ê°€ 
            text = self._post_process_correction(text)

            # í’ˆì§ˆ í•„í„°ë§
            if len(text) < self.stt_quality['min_text_length']:
                return None
            
            # AI ì‘ë‹µ ì§í›„ì—ëŠ” ì ì‹œ ëŒ€ê¸°
            last_ai_time = self.stt_quality.get('last_ai_response_time')
            if last_ai_time:
                time_since_ai = time.time() - last_ai_time
                if time_since_ai < self.stt_quality['min_wait_after_ai']:
                    return None
            
            # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ë“¤ í•„í„°ë§
            short_words = ['ë„¤', 'ì˜ˆ', 'ì‘', 'ì–´', 'ìŒ', 'ë§', 'ê²ƒ', 'ì¢€', 'ê·¸', 'ì´']
            if text.strip() in short_words:
                return None
            
            return text
        except queue.Empty:
            return None
        
    def _post_process_correction(self, text: str) -> str:
        """STT ê²°ê³¼ í›„ì²˜ë¦¬ êµì • ì‘ì—…"""
        corrections = {
            "ì§€ê¸ˆì •ì§€": "ì§€ê¸‰ì •ì§€",
            "ì§€ê¸ˆ ì •ì§€": "ì§€ê¸‰ì •ì§€", 
            "ë³´ì´ìŠ¤ ì‚ì‹±": "ë³´ì´ìŠ¤í”¼ì‹±",
            "ë³´ì´ìŠ¤ì‚ì‹±": "ë³´ì´ìŠ¤í”¼ì‹±",
            "ë³´ì´ìŠ¤ë¯¸ì‹±": "ë³´ì´ìŠ¤í”¼ì‹±",
            "ì¼ ì‚¼ ì´": "132",
            "ì¼ì‚¼ì´": "132", 
            "ì¼ íŒ” ì¼ ì¼": "1811",
            "ì¼íŒ”ì¼ì¼": "1811",
            "ëª…ì˜ ë„ìš©": "ëª…ì˜ë„ìš©",
            "ê³„ì¢Œ ì´ì²´": "ê³„ì¢Œì´ì²´",
            "ì‚¬ê¸° ì‹ ê³ ": "ì‚¬ê¸°ì‹ ê³ "
        }

        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)

        return text
    
    async def _process_user_input_fast(self, user_input: str):
        """ë¹ ë¥¸ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (3ì´ˆ ì´ë‚´ ëª©í‘œ)"""
        
        start_time = time.time()
        self.is_processing = True
        
        logger.info(f"ğŸ‘¤ ì‚¬ìš©ì: {user_input}")
        
        # ìƒíƒœ ë³€ê²½
        self._set_state(ConversationState.PROCESSING)
        
        # ì½œë°± í˜¸ì¶œ
        if self.callbacks['on_user_speech']:
            self.callbacks['on_user_speech'](user_input)
        
        try:
            # LangGraph ë¹ ë¥¸ ì²˜ë¦¬ (2ì´ˆ íƒ€ì„ì•„ì›ƒ)
            self.current_langgraph_state = await asyncio.wait_for(
                self.langgraph.continue_conversation(
                    self.current_langgraph_state, 
                    user_input
                ),
                timeout=2.0
            )
            
            # AI ì‘ë‹µ ë¹ ë¥¸ ì²˜ë¦¬
            await self._handle_ai_response_fast()
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_performance_stats_fast(processing_time)
            
            self.stats['total_turns'] += 1
            
            # ë¹ ë¥¸ ì‘ë‹µ ì²´í¬
            if processing_time <= 3.0:
                self.stats['fast_responses'] += 1
            
            # ë‹¤ìŒ ìƒíƒœë¡œ
            if self._is_conversation_complete_fast():
                await self.stop_conversation()
            else:
                self._set_state(ConversationState.LISTENING)
            
        except asyncio.TimeoutError:
            logger.warning("â° ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ - ë¹ ë¥¸ ì‘ë‹µ ìƒì„±")
            await self._handle_timeout_response_fast(user_input)
        except Exception as e:
            logger.error(f"ì…ë ¥ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self._handle_error_fast("ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        finally:
            self.is_processing = False
    
    async def _handle_ai_response_fast(self):
        """AI ì‘ë‹µ ë¹ ë¥¸ ì²˜ë¦¬"""
        
        if not self.current_langgraph_state or not self.current_langgraph_state.get('messages'):
            return
        
        last_message = self.current_langgraph_state['messages'][-1]
        if last_message.get('role') != 'assistant':
            return
        
        ai_response = last_message['content']
        
        # ì‘ë‹µ ê¸¸ì´ ê°•ì œ ì œí•œ (80ì)
        if len(ai_response) > 80:
            ai_response = ai_response[:77] + "..."
        
        logger.info(f"ğŸ¤– AI: {ai_response}")
        
        # ì½œë°± í˜¸ì¶œ
        if self.callbacks['on_ai_response']:
            self.callbacks['on_ai_response'](ai_response)
        
        # ë¹ ë¥¸ TTS ì²˜ë¦¬
        await self._speak_response_fast(ai_response)
    
    async def _speak_response_fast(self, text: str):
        """ë¹ ë¥¸ TTS ì²˜ë¦¬ (AI ì‘ë‹µ ì‹œê°„ ê¸°ë¡)"""
        
        self._set_state(ConversationState.SPEAKING)
        
        try:
            # ê¸´ê¸‰ë„ ì²´í¬
            is_emergency = any(word in text for word in ['ê¸´ê¸‰', 'ê¸‰í•´', 'ì¦‰ì‹œ', 'ë‹¹ì¥'])
            
            if is_emergency:
                self.stats['emergency_handled'] += 1
                # ì‘ê¸‰ ìƒí™©ìš© TTS ìµœì í™”
                self.tts_service.optimize_for_emergency()
            
            # TTS ìŠ¤íŠ¸ë¦¼ ë¹ ë¥¸ ìƒì„± (2ì´ˆ íƒ€ì„ì•„ì›ƒ)
            audio_stream = await asyncio.wait_for(
                self._create_tts_stream_fast(text),
                timeout=2.0
            )
            
            # ì¦‰ì‹œ ì˜¤ë””ì˜¤ ì¬ìƒ
            await self.audio_manager.play_audio_stream(audio_stream)
            
            # AI ì‘ë‹µ ì‹œê°„ ê¸°ë¡ (STT í•„í„°ë§ìš©)
            self.stt_quality['last_ai_response_time'] = time.time()
            
            logger.info("ğŸ”Š ë¹ ë¥¸ TTS ì™„ë£Œ")
            
        except asyncio.TimeoutError:
            logger.warning("â° TTS ì‹œê°„ ì´ˆê³¼ - í…ìŠ¤íŠ¸ ì¶œë ¥")
            print(f"ğŸ¤– {text}")
            # ì‘ë‹µ ì‹œê°„ ê¸°ë¡
            self.stt_quality['last_ai_response_time'] = time.time()
        except Exception as e:
            logger.error(f"TTS ì˜¤ë¥˜: {e}")
            # TTS ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ì¶œë ¥
            print(f"ğŸ¤– {text}")
            # ì‘ë‹µ ì‹œê°„ ê¸°ë¡
            self.stt_quality['last_ai_response_time'] = time.time()
    
    async def _create_tts_stream_fast(self, text: str):
        """ë¹ ë¥¸ TTS ìŠ¤íŠ¸ë¦¼ ìƒì„±"""
        return self.tts_service.text_to_speech_stream(text)
    
    async def _handle_timeout_response_fast(self, user_input: str):
        """íƒ€ì„ì•„ì›ƒ ì‹œ ë¹ ë¥¸ ì‘ë‹µ"""
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ì‘ë‹µ
        user_lower = user_input.lower()
        
        if any(word in user_lower for word in ['ëˆ', 'ì†¡ê¸ˆ', 'ë³´ëƒˆ', 'ê¸‰í•´']):
            quick_response = "ì¦‰ì‹œ ì¼ì‚¼ì´ë²ˆìœ¼ë¡œ ì „í™”í•˜ì„¸ìš”."
        elif any(word in user_lower for word in ['ì˜ì‹¬', 'ì´ìƒ']):
            quick_response = "ì¼ì‚¼ì´ë²ˆìœ¼ë¡œ ìƒë‹´ë°›ìœ¼ì„¸ìš”."
        else:
            quick_response = "ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì¼ì‚¼ì´ë²ˆìœ¼ë¡œ ì—°ë½í•˜ì„¸ìš”."
        
        # ì§ì ‘ ì‘ë‹µ ì¶”ê°€
        if self.current_langgraph_state:
            self.current_langgraph_state['messages'].append({
                "role": "assistant",
                "content": quick_response,
                "timestamp": datetime.now(),
                "type": "timeout_response"
            })
        
        await self._speak_response_fast(quick_response)
    
    async def _handle_initial_greeting_fast(self):
        """ì´ˆê¸° ì¸ì‚¬ë§ ë¹ ë¥¸ ì²˜ë¦¬"""
        
        if self.current_langgraph_state and self.current_langgraph_state.get('messages'):
            greeting = self.current_langgraph_state['messages'][-1]['content']
            
            # ì¸ì‚¬ë§ë„ ê¸¸ì´ ì œí•œ
            if len(greeting) > 80:
                greeting = "ìƒë‹´ì„¼í„°ì…ë‹ˆë‹¤. ê¸‰í•˜ê²Œ ë„ì›€ì´ í•„ìš”í•œ ìƒí™©ì¸ê°€ìš”?"
            
            logger.info("ğŸ”Š ì´ˆê¸° ì¸ì‚¬ë§ ë¹ ë¥¸ ì¬ìƒ")
            await self._speak_response_fast(greeting)
    
    async def _handle_error_fast(self, error_message: str):
        """ë¹ ë¥¸ ì˜¤ë¥˜ ì²˜ë¦¬"""
        
        self._set_state(ConversationState.ERROR)
        logger.error(f"ë¹ ë¥¸ ì˜¤ë¥˜ ì²˜ë¦¬: {error_message}")
        
        # ê°„ë‹¨í•œ ì˜¤ë¥˜ ë©”ì‹œì§€
        simple_error = "ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¼ì¼ì´ë²ˆìœ¼ë¡œ ì‹ ê³ í•˜ì„¸ìš”."
        await self._speak_response_fast(simple_error)
        
        # ì¦‰ì‹œ ë¦¬ìŠ¤ë‹ ìƒíƒœë¡œ
        self._set_state(ConversationState.LISTENING)
    
    def _should_handle_silence_smart(self) -> bool:
        """ìŠ¤ë§ˆíŠ¸í•œ ì¹¨ë¬µ ì²˜ë¦¬ ì—¬ë¶€ íŒë‹¨"""
        
        if not self.silence_detection['enabled']:
            return False
        
        if self.silence_detection['is_first_interaction']:
            return False
        
        if self.is_processing:
            return False
        
        current_time = time.time()
        
        # AI ì‘ë‹µ ì§í›„ì—ëŠ” ì¶”ê°€ ëŒ€ê¸°
        last_ai_time = self.stt_quality.get('last_ai_response_time')
        if last_ai_time:
            time_since_ai = current_time - last_ai_time
            min_silence_after_ai = self.silence_detection.get('min_silence_after_ai', 3.0)
            if time_since_ai < min_silence_after_ai:
                return False
        
        # ìŒì„± ì¸ì‹ ê¸°ë°˜ ì²´í¬
        last_speech_time = self.silence_detection.get('last_speech_time')
        speech_silence = float('inf')
        if last_speech_time:
            speech_silence = current_time - last_speech_time
        
        # ì˜¤ë””ì˜¤ í™œë™ ê¸°ë°˜ ì²´í¬
        last_audio_time = self.silence_detection.get('last_audio_activity')
        audio_silence = float('inf')
        if last_audio_time:
            audio_silence = current_time - last_audio_time
        
        # ë” ê´€ëŒ€í•œ ì¹¨ë¬µ ì‹œê°„ ì‚¬ìš©
        silence_duration = min(speech_silence, audio_silence)
        
        return silence_duration >= self.silence_detection['timeout']
    
    async def _handle_silence_fast(self):
        """ë¹ ë¥¸ ì¹¨ë¬µ ì²˜ë¦¬"""
        
        logger.info("â° ì¹¨ë¬µ ê°ì§€ - ê°„ë‹¨í•œ í›„ì† ì§ˆë¬¸")
        
        # ì‹œê°„ ë¦¬ì…‹
        self.silence_detection['last_speech_time'] = time.time()
        self.silence_detection['last_audio_activity'] = time.time()
        
        # ê°„ë‹¨í•œ í›„ì† ì§ˆë¬¸
        follow_up = self._generate_simple_follow_up()
        
        # ë¹ ë¥¸ ì „ì†¡
        await self._send_follow_up_fast(follow_up)
    
    def _generate_simple_follow_up(self) -> str:
        """ê°„ë‹¨í•œ í›„ì† ì§ˆë¬¸ ìƒì„±"""
        
        if not self.current_langgraph_state:
            return "ë” ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"
        
        urgency = self.current_langgraph_state.get('urgency_level', 3)
        
        if urgency >= 8:
            return "ì§€ê¸ˆ ì¡°ì¹˜í•˜ê³  ê³„ì‹ ê°€ìš”?"
        elif urgency >= 6:
            return "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"
        else:
            return "ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•˜ì„¸ìš”."
    
    async def _send_follow_up_fast(self, question: str):
        """ë¹ ë¥¸ í›„ì† ì§ˆë¬¸ ì „ì†¡"""
        
        try:
            # LangGraph ìƒíƒœì— ì¶”ê°€
            if self.current_langgraph_state:
                self.current_langgraph_state['messages'].append({
                    "role": "assistant",
                    "content": question,
                    "timestamp": datetime.now(),
                    "metadata": {"type": "follow_up_silence"}
                })
            
            # ì½œë°± í˜¸ì¶œ
            if self.callbacks['on_ai_response']:
                self.callbacks['on_ai_response'](question)
            
            # ë¹ ë¥¸ TTS ì¬ìƒ
            await self._speak_response_fast(question)
            
        except Exception as e:
            logger.error(f"í›„ì† ì§ˆë¬¸ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    def _should_end_conversation_fast(self) -> bool:
        """ë¹ ë¥¸ ëŒ€í™” ì¢…ë£Œ íŒë‹¨"""
        
        if not self.current_langgraph_state:
            return False
        
        # ì™„ë£Œ ìƒíƒœ ì²´í¬
        if self.current_langgraph_state.get('current_step') == 'consultation_complete':
            return True
        
        # í„´ ìˆ˜ ì²´í¬ (8í„´ìœ¼ë¡œ ì œí•œ)
        if self.stats['total_turns'] >= 8:
            return True
        
        # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ (10ë¶„)
        if self.stats['conversation_start_time']:
            elapsed = (datetime.now() - self.stats['conversation_start_time']).total_seconds()
            if elapsed > 600:  # 10ë¶„
                return True
        
        return False
    
    def _is_conversation_complete_fast(self) -> bool:
        """ë¹ ë¥¸ ëŒ€í™” ì™„ë£Œ í™•ì¸"""
        return self._should_end_conversation_fast()
    
    def _update_performance_stats_fast(self, processing_time: float):
        """ë¹ ë¥¸ ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        # ì‘ë‹µ ì‹œê°„ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
        self.response_times.append(processing_time)
        
        if len(self.response_times) > self.max_response_history:
            self.response_times.pop(0)
        
        # í‰ê·  ê³„ì‚°
        if self.response_times:
            self.stats['avg_response_time'] = sum(self.response_times) / len(self.response_times)
    
    def _set_state(self, new_state: ConversationState):
        """ë¹ ë¥¸ ìƒíƒœ ë³€ê²½"""
        
        if self.conversation_state != new_state:
            old_state = self.conversation_state
            self.conversation_state = new_state
            
            # ì½œë°± í˜¸ì¶œ
            if self.callbacks['on_state_change']:
                self.callbacks['on_state_change'](old_state, new_state)
    
    async def stop_conversation(self):
        """ë¹ ë¥¸ ëŒ€í™” ì¤‘ì§€"""
        
        logger.info("ğŸ›‘ ëŒ€í™” ì¤‘ì§€")
        
        self.is_running = False
        self.is_listening = False
        
        # ê°„ë‹¨í•œ ë§ˆì§€ë§‰ ì¸ì‚¬
        farewell = "ìƒë‹´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        await self._speak_response_fast(farewell)
    
    async def cleanup(self):
        """ë¹ ë¥¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        
        logger.info("ğŸ§¹ ìŒì„± ì¹œí™”ì  ë§¤ë‹ˆì € ì •ë¦¬ ì¤‘...")
        
        try:
            self.is_running = False
            self.is_listening = False
            self.is_processing = False
            
            # STT ì •ë¦¬
            if self.stt_client and hasattr(self.stt_client, 'stream'):
                try:
                    self.stt_client.stream.terminate()
                except:
                    pass
            
            # í ì •ë¦¬
            while not self.stt_queue.empty():
                try:
                    self.stt_queue.get_nowait()
                except queue.Empty:
                    break
            
            # ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì •ë¦¬
            self.audio_manager.cleanup()
            
            # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
            self._print_simple_stats()
            
            logger.info("âœ… ìŒì„± ì¹œí™”ì  ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _print_simple_stats(self):
        """ê°„ë‹¨í•œ ì„±ëŠ¥ í†µê³„ ì¶œë ¥"""
        
        stats = self.stats
        
        if stats['conversation_start_time']:
            total_time = (datetime.now() - stats['conversation_start_time']).total_seconds()
            fast_rate = (stats['fast_responses'] / max(stats['total_turns'], 1)) * 100
            
            logger.info("ğŸ“Š ìŒì„± ì¹œí™”ì  í†µê³„:")
            logger.info(f"   ì´ ëŒ€í™” ì‹œê°„: {total_time:.1f}ì´ˆ")
            logger.info(f"   ì´ ëŒ€í™” í„´: {stats['total_turns']}")
            logger.info(f"   ë¹ ë¥¸ ì‘ë‹µë¥ : {fast_rate:.1f}%")
            logger.info(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['avg_response_time']:.3f}ì´ˆ")
            logger.info(f"   ì‘ê¸‰ ì²˜ë¦¬: {stats['emergency_handled']}íšŒ")
    
    # ========================================================================
    # ê³µê°œ ë©”ì„œë“œë“¤
    # ========================================================================
    
    def get_conversation_status(self) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ëŒ€í™” ìƒíƒœ ì •ë³´"""
        
        elapsed_time = 0
        if self.stats['conversation_start_time']:
            elapsed_time = (datetime.now() - self.stats['conversation_start_time']).total_seconds()
        
        return {
            "state": self.conversation_state.value,
            "session_id": self.session_id,
            "total_turns": self.stats['total_turns'],
            "is_running": self.is_running,
            "is_listening": self.is_listening,
            "is_processing": self.is_processing,
            "elapsed_time": elapsed_time,
            "avg_response_time": self.stats['avg_response_time'],
            "fast_response_rate": f"{(self.stats['fast_responses'] / max(self.stats['total_turns'], 1)) * 100:.1f}%",
            "emergency_handled": self.stats['emergency_handled']
        }
    
    def set_callbacks(self, 
                     on_user_speech: Optional[Callable] = None,
                     on_ai_response: Optional[Callable] = None, 
                     on_state_change: Optional[Callable] = None):
        """ì½œë°± í•¨ìˆ˜ ì„¤ì •"""
        
        if on_user_speech:
            self.callbacks['on_user_speech'] = on_user_speech
        if on_ai_response:
            self.callbacks['on_ai_response'] = on_ai_response
        if on_state_change:
            self.callbacks['on_state_change'] = on_state_change
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ì„±ëŠ¥ ì§€í‘œ"""
        
        return {
            **self.stats,
            "current_queue_size": self.stt_queue.qsize(),
            "response_time_history": self.response_times.copy(),
            "audio_level": self.audio_monitor.get('audio_level', 0.0),
            "is_monitoring": self.audio_monitor.get('is_monitoring', False)
        }
    
    def get_audio_status(self) -> dict:
        """ì˜¤ë””ì˜¤ ìƒíƒœ ì¡°íšŒ"""
        
        current_time = time.time()
        
        return {
            'is_monitoring': self.audio_monitor['is_monitoring'],
            'current_audio_level': self.audio_monitor['audio_level'],
            'silence_threshold': self.audio_monitor['silence_threshold'],
            'last_audio_time': self.audio_monitor.get('last_audio_time'),
            'seconds_since_audio': (
                current_time - self.audio_monitor['last_audio_time'] 
                if self.audio_monitor.get('last_audio_time') else None
            ),
            'silence_timeout': self.silence_detection['timeout']
        }


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
ConversationManager = VoiceFriendlyConversationManager
HighPerformanceConversationManager = VoiceFriendlyConversationManager